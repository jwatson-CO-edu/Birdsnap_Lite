{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69806ffe-0f01-4b13-9894-2e5cb08bf2bf",
   "metadata": {},
   "source": [
    "# The goal of this notebook is to make BirdSnap fit in 10GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f7f76c5-f2d6-4a89-9596-4b309832a335",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39f3c646-12a6-402b-a7f9-266e3fe22c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.10.15 (main, Sep  7 2024, 18:35:33) [GCC 9.4.0]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print( sys.version )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e603474-714d-43a8-bb6f-47c5a6c7dcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "_DATASET_FOLDR = \"data\"\n",
    "_DATASET_INAME = \"birdsnapLite.hf\"\n",
    "_DATASET_LNAME = \"birdsnapLite_Final\"\n",
    "_DATASET_IPATH = os.path.join( _DATASET_FOLDR, _DATASET_INAME )\n",
    "_DATASET_LPATH = os.path.join( _DATASET_FOLDR, _DATASET_LNAME )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eca61b9-e3b3-4317-b2f2-514fa1a2614f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds = load_dataset( \"sasha/birdsnap\" )\n",
    "ds = load_dataset( \"isaacchung/birdsnap\" )\n",
    "print( type( ds ) )\n",
    "print( sys.getsizeof( ds ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f4454f-cc5d-4886-af1b-d6735b945725",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.save_to_disk( _DATASET_IPATH )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76eafc35-83e5-47d7-98ff-b6c39ded9bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datasets import Dataset, load_from_disk\n",
    "import torchvision.transforms as T\n",
    "\n",
    "_IMG_SIZ = (64, 64)\n",
    "\n",
    "\n",
    "def crop_and_rescale( img_tensor, bbox, size = _IMG_SIZ ):\n",
    "    \"\"\" Crop the region inside the bounding box and resize it to the given size. \"\"\"\n",
    "    # Extract the bounding box coordinates\n",
    "    x_min, y_min, x_max, y_max = bbox\n",
    "\n",
    "    # Crop the image tensor to the bounding box region\n",
    "    cropped_img = img_tensor[:, y_min:y_max, x_min:x_max]  # Cropping the image\n",
    "    \n",
    "    # Resize the cropped image to the target size (64x64)\n",
    "    resize_transform = T.Resize( size )\n",
    "    resized_img = resize_transform( cropped_img )\n",
    "    \n",
    "    return resized_img\n",
    "    \n",
    "\n",
    "class BSL_Maker( Dataset ):\n",
    "    \"\"\" Load the BirdSnap Dataset in order to reduce it \"\"\"\n",
    "    \n",
    "    def __init__( self, train = True ):\n",
    "        \"\"\" Load the local dataset to be reduced \"\"\"\n",
    "        trnInfo = None\n",
    "        tstInfo = None\n",
    "        valInfo = None\n",
    "        with open( f\"{_DATASET_IPATH}/train/dataset_info.json\" ) as json_data:\n",
    "            trnInfo = json.load( json_data )\n",
    "        with open( f\"{_DATASET_IPATH}/test/dataset_info.json\" ) as json_data:\n",
    "            tstInfo = json.load( json_data )\n",
    "        with open( f\"{_DATASET_IPATH}/val/dataset_info.json\" ) as json_data:\n",
    "            valInfo = json.load( json_data )\n",
    "        \n",
    "        self.dataset   = load_from_disk( _DATASET_IPATH )\n",
    "        self.transform = T.ToTensor()\n",
    "        self.labels    = {\n",
    "            'train' : { 'common' : trnInfo['features']['common']['names'], 'scientific' : trnInfo['features']['scientific']['names'] },\n",
    "            'test'  : { 'common' : tstInfo['features']['common']['names'], 'scientific' : tstInfo['features']['scientific']['names'] },\n",
    "            'val'   : { 'common' : valInfo['features']['common']['names'], 'scientific' : valInfo['features']['scientific']['names'] },\n",
    "        }\n",
    "\n",
    "    \n",
    "    def len_split( self, splitName ):\n",
    "        \"\"\" Return the number of examples \"\"\"\n",
    "        return self.dataset.num_rows[ splitName ]\n",
    "\n",
    "\n",
    "    def get_split_item( self, i, splitName = \"train\" ):\n",
    "        \"\"\" Fetch an example from the dataset \"\"\"\n",
    "        img = self.dataset[ splitName ][i][\"image\"]\n",
    "        img = self.transform( img )\n",
    "        \n",
    "        bb  = [ self.dataset[ splitName ][i][\"bb_x1\"], self.dataset[ splitName ][i][\"bb_y1\"], \n",
    "                self.dataset[ splitName ][i][\"bb_x2\"], self.dataset[ splitName ][i][\"bb_y2\"], ]\n",
    "        img = crop_and_rescale( img, bb, size = _IMG_SIZ )\n",
    "        \n",
    "        return {\n",
    "            \"image\"         : img.detach().clone(), \n",
    "            'common'        : self.labels[ splitName ][\"common\"][ self.dataset[ splitName ][i][\"common\"] ], \n",
    "            'scientific'    : self.labels[ splitName ][\"scientific\"][ self.dataset[ splitName ][i][\"scientific\"] ], \n",
    "            'common_idx'    : self.dataset[ splitName ][i][\"common\"], \n",
    "            'scientific_idx': self.dataset[ splitName ][i][\"scientific\"], \n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7d19ff83-fdb6-4486-b6aa-36436482ca57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5493c31e2e374394b3cc8c56f14b1d24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset from disk:   0%|          | 0/133 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38098\n",
      "1851\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "bsl = BSL_Maker()\n",
    "print( bsl.len_split( \"train\" ) )\n",
    "print( bsl.len_split( \"test\" ) )\n",
    "print( bsl.len_split( \"val\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4c8bc8ee-c332-486a-877b-f22ce273502f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train....................................................................................................................................................................................\n",
      "Skipped item 8964 because image file is truncated (45 bytes not processed)\n",
      ".........................................................................................................................................................\n",
      "Skipped item 16648 because Input and output sizes should be greater than 0, but got input (H: 216, W: 0) output (H: 64, W: 64)\n",
      "...................................................................................................................................................."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/james/.local/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:900: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".........................................................................................................................................................................................................................................................................................\n",
      "test......................................\n",
      "val.\n",
      "Reduction process took 3.8842570026053322 hours!\n"
     ]
    }
   ],
   "source": [
    "import sys, time\n",
    "now = time.time\n",
    "\n",
    "_SKIP_DIV =  1\n",
    "_SHOW_DIV = 50\n",
    "\n",
    "data = {}\n",
    "elemNames = [\"image\", 'common', 'scientific', 'common_idx', 'scientific_idx']\n",
    "\n",
    "bgn = now()\n",
    "for partName in [\"train\", \"test\", \"val\"]:\n",
    "    print( partName, end = '', flush = True )\n",
    "    N = bsl.len_split( partName )\n",
    "    data[ partName ] = {\n",
    "        \"image\"         : list(), \n",
    "        'common'        : list(), \n",
    "        'scientific'    : list(), \n",
    "        'common_idx'    : list(), \n",
    "        'scientific_idx': list(), \n",
    "    }\n",
    "    for i in range(N):\n",
    "        if ((i % _SKIP_DIV) == 0):\n",
    "            try: \n",
    "                item = bsl.get_split_item( i, partName )\n",
    "                for elemNam in elemNames:\n",
    "                    data[ partName ][ elemNam ].append( item[ elemNam ] )\n",
    "            except Exception as e:\n",
    "                print( f\"\\nSkipped item {i} because {e}\" )\n",
    "        if ((i % _SHOW_DIV) == 0):\n",
    "            print( '.', end = '', flush = True )\n",
    "    print()\n",
    "end = now()\n",
    "print( f\"Reduction process took {(end-bgn)/60.0/60.0} hours!\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "00c442e6-9a14-4f45-bf2b-12eb874573aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset.from_dict( data[\"train\"] )\n",
    "test_dataset  = Dataset.from_dict( data[\"test\"] )\n",
    "val_dataset   = Dataset.from_dict( data[\"val\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b7da978b-ce8c-49e5-adf6-7f6504449065",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import DatasetDict\n",
    "dataset_dict = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'test' : test_dataset ,\n",
    "    'val'  : val_dataset  ,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9d0f3246-2566-4804-949d-916724c5903c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92c0bc146f6d49569fff5359ffc6fe1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/4 shards):   0%|          | 0/38096 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b52238a0137249ed9a83d44cb728b235",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/1851 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f50262b64f24818bdc0161a6823e59b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/7 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_dict.save_to_disk( _DATASET_LPATH )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4b8f634c-ee5e-49a4-92d9-5bb0bc48e36a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55df19d5ed0b4f309dd11c159805a245",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efcef7015153405c8d8e9d2fafe78100",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18913477fe404b16abaf1aa2ee6140f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ab2513c7cc14f9286338bed6dc82756",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23cad05dc86f46fda9b782581bee50b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2095629bd3ba4969b9f2e1d9702b196c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02eb86e3d6114d3bb4435c995de72337",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3a512585d424074bd3fdf43e46bb0a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d27ffe687b9440d5963a904d2578d99e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34de8adf57d045828e11b8f8963771d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/223 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/jwatson-CO-edu/birdsnap_lite/commit/9bcf097b2dd9ab1af578cf6d927446baa83888b3', commit_message='Upload dataset', commit_description='', oid='9bcf097b2dd9ab1af578cf6d927446baa83888b3', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/jwatson-CO-edu/birdsnap_lite', endpoint='https://huggingface.co', repo_type='dataset', repo_id='jwatson-CO-edu/birdsnap_lite'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# term$> huggingface-cli login\n",
    "# Make sure that the token has WRITE permissions!\n",
    "dataset_dict.push_to_hub( \"jwatson-CO-edu/birdsnap_lite\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f28129a-e11a-4343-8c96-55ebe77656dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
