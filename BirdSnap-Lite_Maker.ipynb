{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69806ffe-0f01-4b13-9894-2e5cb08bf2bf",
   "metadata": {},
   "source": [
    "# The goal of this notebook is to make BirdSnap fit in 10GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e73beac-152a-4a75-8e37-3ef63dbb78c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "_DATASET_FOLDR = \"data\"\n",
    "_DATASET_INAME = \"birdsnapLite.hf\"\n",
    "_DATASET_LNAME = \"birdsnapLite_256\"\n",
    "_DATASET_IPATH = os.path.join( _DATASET_FOLDR, _DATASET_INAME )\n",
    "_DATASET_LPATH = os.path.join( _DATASET_FOLDR, _DATASET_LNAME )\n",
    "\n",
    "from datasets import load_dataset\n",
    "if not os.path.isdir( _DATASET_IPATH ):\n",
    "    ds = load_dataset( \"isaacchung/birdsnap\" )\n",
    "    ds.save_to_disk( _DATASET_IPATH )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76eafc35-83e5-47d7-98ff-b6c39ded9bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datasets import Dataset, load_from_disk\n",
    "import torchvision.transforms as T\n",
    "\n",
    "_IMG_SIZ = (256, 256)\n",
    "\n",
    "\n",
    "def crop_and_rescale( img_tensor, bbox, size = _IMG_SIZ ):\n",
    "    \"\"\" Crop the region inside the bounding box and resize it to the given size. \"\"\"\n",
    "    # Extract the bounding box coordinates\n",
    "    x_min, y_min, x_max, y_max = bbox\n",
    "\n",
    "    # Crop the image tensor to the bounding box region\n",
    "    cropped_img = img_tensor[:, y_min:y_max, x_min:x_max]  # Cropping the image\n",
    "    \n",
    "    # Resize the cropped image to the target size (64x64)\n",
    "    resize_transform = T.Resize( size )\n",
    "    resized_img = resize_transform( cropped_img )\n",
    "    \n",
    "    return resized_img\n",
    "    \n",
    "\n",
    "class BSL_Maker( Dataset ):\n",
    "    \"\"\" Load the BirdSnap Dataset in order to reduce it \"\"\"\n",
    "    \n",
    "    def __init__( self, train = True ):\n",
    "        \"\"\" Load the local dataset to be reduced \"\"\"\n",
    "        trnInfo = None\n",
    "        tstInfo = None\n",
    "        valInfo = None\n",
    "        with open( f\"{_DATASET_IPATH}/train/dataset_info.json\" ) as json_data:\n",
    "            trnInfo = json.load( json_data )\n",
    "        with open( f\"{_DATASET_IPATH}/test/dataset_info.json\" ) as json_data:\n",
    "            tstInfo = json.load( json_data )\n",
    "        with open( f\"{_DATASET_IPATH}/val/dataset_info.json\" ) as json_data:\n",
    "            valInfo = json.load( json_data )\n",
    "        \n",
    "        self.dataset   = load_from_disk( _DATASET_IPATH )\n",
    "        self.transform = T.ToTensor()\n",
    "        self.labels    = {\n",
    "            'train' : { 'common' : trnInfo['features']['common']['names'], 'scientific' : trnInfo['features']['scientific']['names'] },\n",
    "            'test'  : { 'common' : tstInfo['features']['common']['names'], 'scientific' : tstInfo['features']['scientific']['names'] },\n",
    "            'val'   : { 'common' : valInfo['features']['common']['names'], 'scientific' : valInfo['features']['scientific']['names'] },\n",
    "        }\n",
    "\n",
    "    \n",
    "    def len_split( self, splitName ):\n",
    "        \"\"\" Return the number of examples \"\"\"\n",
    "        return self.dataset.num_rows[ splitName ]\n",
    "\n",
    "\n",
    "    def get_split_item( self, i, splitName = \"train\" ):\n",
    "        \"\"\" Fetch an example from the dataset \"\"\"\n",
    "        img = self.dataset[ splitName ][i][\"image\"]\n",
    "        img = self.transform( img )\n",
    "        \n",
    "        bb  = [ self.dataset[ splitName ][i][\"bb_x1\"], self.dataset[ splitName ][i][\"bb_y1\"], \n",
    "                self.dataset[ splitName ][i][\"bb_x2\"], self.dataset[ splitName ][i][\"bb_y2\"], ]\n",
    "        img = crop_and_rescale( img, bb, size = _IMG_SIZ )\n",
    "        \n",
    "        return {\n",
    "            \"image\"         : img.detach().clone(), \n",
    "            'common'        : self.labels[ splitName ][\"common\"][ self.dataset[ splitName ][i][\"common\"] ], \n",
    "            'scientific'    : self.labels[ splitName ][\"scientific\"][ self.dataset[ splitName ][i][\"scientific\"] ], \n",
    "            'common_idx'    : self.dataset[ splitName ][i][\"common\"], \n",
    "            'scientific_idx': self.dataset[ splitName ][i][\"scientific\"], \n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2f9d9f9-6bc8-4086-a9f2-2f336fad95a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1b213200b72440e80ef98f63efecba1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset from disk:   0%|          | 0/133 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train....................................................................................................................................................................................\n",
      "Skipped item 8964 because image file is truncated (45 bytes not processed)\n",
      "................"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 26\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((i \u001b[38;5;241m%\u001b[39m _SKIP_DIV) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m: \n\u001b[0;32m---> 26\u001b[0m         item \u001b[38;5;241m=\u001b[39m \u001b[43mbsl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_split_item\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartName\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m elemNam \u001b[38;5;129;01min\u001b[39;00m elemNames:\n\u001b[1;32m     28\u001b[0m             data[ partName ][ elemNam ]\u001b[38;5;241m.\u001b[39mappend( item[ elemNam ] )\n",
      "Cell \u001b[0;32mIn[2], line 66\u001b[0m, in \u001b[0;36mBSL_Maker.get_split_item\u001b[0;34m(self, i, splitName)\u001b[0m\n\u001b[1;32m     57\u001b[0m bb  \u001b[38;5;241m=\u001b[39m [ \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[ splitName ][i][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbb_x1\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[ splitName ][i][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbb_y1\u001b[39m\u001b[38;5;124m\"\u001b[39m], \n\u001b[1;32m     58\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[ splitName ][i][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbb_x2\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[ splitName ][i][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbb_y2\u001b[39m\u001b[38;5;124m\"\u001b[39m], ]\n\u001b[1;32m     59\u001b[0m img \u001b[38;5;241m=\u001b[39m crop_and_rescale( img, bb, size \u001b[38;5;241m=\u001b[39m _IMG_SIZ )\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m\"\u001b[39m         : img\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mclone(), \n\u001b[1;32m     63\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcommon\u001b[39m\u001b[38;5;124m'\u001b[39m        : \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels[ splitName ][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcommon\u001b[39m\u001b[38;5;124m\"\u001b[39m][ \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[ splitName ][i][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcommon\u001b[39m\u001b[38;5;124m\"\u001b[39m] ], \n\u001b[1;32m     64\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscientific\u001b[39m\u001b[38;5;124m'\u001b[39m    : \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels[ splitName ][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscientific\u001b[39m\u001b[38;5;124m\"\u001b[39m][ \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[ splitName ][i][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscientific\u001b[39m\u001b[38;5;124m\"\u001b[39m] ], \n\u001b[1;32m     65\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcommon_idx\u001b[39m\u001b[38;5;124m'\u001b[39m    : \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[ splitName ][i][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcommon\u001b[39m\u001b[38;5;124m\"\u001b[39m], \n\u001b[0;32m---> 66\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscientific_idx\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43m \u001b[49m\u001b[43msplitName\u001b[49m\u001b[43m \u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscientific\u001b[39m\u001b[38;5;124m\"\u001b[39m], \n\u001b[1;32m     67\u001b[0m }\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/datasets/arrow_dataset.py:2742\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2740\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):  \u001b[38;5;66;03m# noqa: F811\u001b[39;00m\n\u001b[1;32m   2741\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Can be used to index columns (by string names) or rows (by integer index or iterable of indices or bools).\"\"\"\u001b[39;00m\n\u001b[0;32m-> 2742\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/datasets/arrow_dataset.py:2727\u001b[0m, in \u001b[0;36mDataset._getitem\u001b[0;34m(self, key, **kwargs)\u001b[0m\n\u001b[1;32m   2725\u001b[0m formatter \u001b[38;5;241m=\u001b[39m get_formatter(format_type, features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info\u001b[38;5;241m.\u001b[39mfeatures, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mformat_kwargs)\n\u001b[1;32m   2726\u001b[0m pa_subtable \u001b[38;5;241m=\u001b[39m query_table(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data, key, indices\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_indices)\n\u001b[0;32m-> 2727\u001b[0m formatted_output \u001b[38;5;241m=\u001b[39m \u001b[43mformat_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2728\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpa_subtable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformatter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformatter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformat_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformat_columns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_all_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_all_columns\u001b[49m\n\u001b[1;32m   2729\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2730\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m formatted_output\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/datasets/formatting/formatting.py:639\u001b[0m, in \u001b[0;36mformat_table\u001b[0;34m(table, key, formatter, format_columns, output_all_columns)\u001b[0m\n\u001b[1;32m    637\u001b[0m python_formatter \u001b[38;5;241m=\u001b[39m PythonFormatter(features\u001b[38;5;241m=\u001b[39mformatter\u001b[38;5;241m.\u001b[39mfeatures)\n\u001b[1;32m    638\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m format_columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 639\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mformatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    640\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumn\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    641\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m format_columns:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/datasets/formatting/formatting.py:403\u001b[0m, in \u001b[0;36mFormatter.__call__\u001b[0;34m(self, pa_table, query_type)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pa_table: pa\u001b[38;5;241m.\u001b[39mTable, query_type: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[RowFormat, ColumnFormat, BatchFormat]:\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrow\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 403\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_row\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumn\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    405\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat_column(pa_table)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/datasets/formatting/formatting.py:444\u001b[0m, in \u001b[0;36mPythonFormatter.format_row\u001b[0;34m(self, pa_table)\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m LazyRow(pa_table, \u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    443\u001b[0m row \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpython_arrow_extractor()\u001b[38;5;241m.\u001b[39mextract_row(pa_table)\n\u001b[0;32m--> 444\u001b[0m row \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpython_features_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode_row\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m row\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/datasets/formatting/formatting.py:222\u001b[0m, in \u001b[0;36mPythonFeaturesDecoder.decode_row\u001b[0;34m(self, row)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode_row\u001b[39m(\u001b[38;5;28mself\u001b[39m, row: \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m:\n\u001b[0;32m--> 222\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode_example\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures \u001b[38;5;28;01melse\u001b[39;00m row\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/datasets/features/features.py:2041\u001b[0m, in \u001b[0;36mFeatures.decode_example\u001b[0;34m(self, example, token_per_repo_id)\u001b[0m\n\u001b[1;32m   2027\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode_example\u001b[39m(\u001b[38;5;28mself\u001b[39m, example: \u001b[38;5;28mdict\u001b[39m, token_per_repo_id: Optional[Dict[\u001b[38;5;28mstr\u001b[39m, Union[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   2028\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Decode example with custom feature decoding.\u001b[39;00m\n\u001b[1;32m   2029\u001b[0m \n\u001b[1;32m   2030\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2038\u001b[0m \u001b[38;5;124;03m        `dict[str, Any]`\u001b[39;00m\n\u001b[1;32m   2039\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2041\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m   2042\u001b[0m         column_name: decode_nested_example(feature, value, token_per_repo_id\u001b[38;5;241m=\u001b[39mtoken_per_repo_id)\n\u001b[1;32m   2043\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_column_requires_decoding[column_name]\n\u001b[1;32m   2044\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m value\n\u001b[1;32m   2045\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m column_name, (feature, value) \u001b[38;5;129;01min\u001b[39;00m zip_dict(\n\u001b[1;32m   2046\u001b[0m             {key: value \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m example}, example\n\u001b[1;32m   2047\u001b[0m         )\n\u001b[1;32m   2048\u001b[0m     }\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/datasets/features/features.py:2042\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   2027\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode_example\u001b[39m(\u001b[38;5;28mself\u001b[39m, example: \u001b[38;5;28mdict\u001b[39m, token_per_repo_id: Optional[Dict[\u001b[38;5;28mstr\u001b[39m, Union[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   2028\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Decode example with custom feature decoding.\u001b[39;00m\n\u001b[1;32m   2029\u001b[0m \n\u001b[1;32m   2030\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2038\u001b[0m \u001b[38;5;124;03m        `dict[str, Any]`\u001b[39;00m\n\u001b[1;32m   2039\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   2041\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[0;32m-> 2042\u001b[0m         column_name: \u001b[43mdecode_nested_example\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken_per_repo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_per_repo_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2043\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_column_requires_decoding[column_name]\n\u001b[1;32m   2044\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m value\n\u001b[1;32m   2045\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m column_name, (feature, value) \u001b[38;5;129;01min\u001b[39;00m zip_dict(\n\u001b[1;32m   2046\u001b[0m             {key: value \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m example}, example\n\u001b[1;32m   2047\u001b[0m         )\n\u001b[1;32m   2048\u001b[0m     }\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/datasets/features/features.py:1403\u001b[0m, in \u001b[0;36mdecode_nested_example\u001b[0;34m(schema, obj, token_per_repo_id)\u001b[0m\n\u001b[1;32m   1400\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(schema, (Audio, Image)):\n\u001b[1;32m   1401\u001b[0m     \u001b[38;5;66;03m# we pass the token to read and decode files from private repositories in streaming mode\u001b[39;00m\n\u001b[1;32m   1402\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m schema\u001b[38;5;241m.\u001b[39mdecode:\n\u001b[0;32m-> 1403\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mschema\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode_example\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken_per_repo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_per_repo_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1404\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/datasets/features/image.py:188\u001b[0m, in \u001b[0;36mImage.decode_example\u001b[0;34m(self, value, token_per_repo_id)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m     image \u001b[38;5;241m=\u001b[39m PIL\u001b[38;5;241m.\u001b[39mImage\u001b[38;5;241m.\u001b[39mopen(BytesIO(bytes_))\n\u001b[0;32m--> 188\u001b[0m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# to avoid \"Too many open files\" errors\u001b[39;00m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m image\u001b[38;5;241m.\u001b[39mgetexif()\u001b[38;5;241m.\u001b[39mget(PIL\u001b[38;5;241m.\u001b[39mImage\u001b[38;5;241m.\u001b[39mExifTags\u001b[38;5;241m.\u001b[39mBase\u001b[38;5;241m.\u001b[39mOrientation) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    190\u001b[0m     image \u001b[38;5;241m=\u001b[39m PIL\u001b[38;5;241m.\u001b[39mImageOps\u001b[38;5;241m.\u001b[39mexif_transpose(image)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/PIL/ImageFile.py:293\u001b[0m, in \u001b[0;36mImageFile.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(msg)\n\u001b[1;32m    292\u001b[0m b \u001b[38;5;241m=\u001b[39m b \u001b[38;5;241m+\u001b[39m s\n\u001b[0;32m--> 293\u001b[0m n, err_code \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    295\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "bsl = BSL_Maker()\n",
    "\n",
    "import sys, time\n",
    "now = time.time\n",
    "\n",
    "_SKIP_DIV =  1\n",
    "_SHOW_DIV = 50\n",
    "\n",
    "data = {}\n",
    "elemNames = [\"image\", 'common', 'scientific', 'common_idx', 'scientific_idx']\n",
    "\n",
    "bgn = now()\n",
    "for partName in [\"train\", \"test\", \"val\"]:\n",
    "    print( partName, end = '', flush = True )\n",
    "    N = bsl.len_split( partName )\n",
    "    data[ partName ] = {\n",
    "        \"image\"         : list(), \n",
    "        'common'        : list(), \n",
    "        'scientific'    : list(), \n",
    "        'common_idx'    : list(), \n",
    "        'scientific_idx': list(), \n",
    "    }\n",
    "    for i in range(N):\n",
    "        if ((i % _SKIP_DIV) == 0):\n",
    "            try: \n",
    "                item = bsl.get_split_item( i, partName )\n",
    "                for elemNam in elemNames:\n",
    "                    data[ partName ][ elemNam ].append( item[ elemNam ] )\n",
    "            except Exception as e:\n",
    "                print( f\"\\nSkipped item {i} because {e}\" )\n",
    "        if ((i % _SHOW_DIV) == 0):\n",
    "            print( '.', end = '', flush = True )\n",
    "    print()\n",
    "end = now()\n",
    "print( f\"Reduction process took {(end-bgn)/60.0/60.0} hours!\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59983c37-8272-45be-8b02-44ae7733258e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset.from_dict( data[\"train\"] )\n",
    "test_dataset  = Dataset.from_dict( data[\"test\"] )\n",
    "val_dataset   = Dataset.from_dict( data[\"val\"] )\n",
    "\n",
    "from datasets import DatasetDict\n",
    "dataset_dict = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'test' : test_dataset ,\n",
    "    'val'  : val_dataset  ,\n",
    "})\n",
    "\n",
    "dataset_dict.save_to_disk( _DATASET_LPATH )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8f634c-ee5e-49a4-92d9-5bb0bc48e36a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# term$> huggingface-cli login\n",
    "# Make sure that the token has WRITE permissions!\n",
    "dataset_dict.push_to_hub( \"jwatson-CO-edu/birdsnap_lite\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f28129a-e11a-4343-8c96-55ebe77656dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
